{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification results\n",
    "\n",
    "We knew we wanted to use 3 classifiers on each of these datasets. Since we have a boolean class, we wanetd to be beating the random 50-50 chance so we included the Random Classifier. We also had good results with Naive Bayes and Decision Trees during the year so we included those as well. Finally, we wrote a new classifier called MyRandomForestClassifier which uses a new type of learning called ensemble learning. \n",
    "\n",
    "|ACCURACY|MyRandomClassifier|MyNaiveBayesClassifier|MyDecisionTreeClassifier|MyRandomForestClassifier|\n",
    "|----|----|----|----|----|\n",
    "|Seattle|0.52|0.69|0.62|0.65|\n",
    "|Melbourne|0.63|0.82|0.71|0.65|\n",
    "|Sydney|0.64|0.84|0.73|0.59|\n",
    "\n",
    "\n",
    "The design was test driven for all of the classifiers based on desk checks performed previously in the semester. The random forest algorithm is very hard to test because of its randomness. Each of the classifiers was evaluated based on its accuracy in predicting class labels for the given test set after training on a large subset of the intial data. We used 3 different comparisons; `train_test_split`, `random_stratified_split`, and `stratified_kfold_cross_validation` for our data. The first is a simple holdout method, the second is a method I wrote to randomly, but stratifically, assign instances to either training or testing sets, and the final was our stratified k-fold variation. All of these gave very similar results but we took the average of each to get the table above. This gave us a wide idea of how our classifier performed as we attempted to remove as much deivation due to the random nature as possible. We used accuracy because we had a boolean class which allowed us to not worry as much about the distribution and instead focus on the randomness explained above.\n",
    "\n",
    "## Analysis \n",
    "Technically, the best was Naive Bayes but it takes a very long time for the alogrithm to run each time, so Eric and I decided that a pickled decision tree would be our \"best\" classifier. Interestingly, the Seattle dataset consistently had the worst predictive accuracy of all the datasets. Eric and I hypothesize that this is due to the lower number of available attributes to use.\n",
    " \n",
    "To see our app in action:\n",
    "1. Visit https://rain-app-eric-caleb.herokuapp.com \n",
    "1. Input endpoints in result? \n",
    "    + \"DATE\" = att0 = 'year-month' \n",
    "    + \"TMAX\" = att1 = 'float' (high temp in F)\n",
    "    + \"TMIN\" = att2 = 'float' (low temp in F) \n",
    "    + Example: https://rain-app-eric-caleb.herokuapp.com/predict?att0=13-Aug&att1=89.0&att2=54.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Dataset\n",
    "We pared down the Australia dataset into a Sydney and a Melbourne dataset which had 15 attributes each and around 3000 instances. The Seattle dataset we cut down from 79 years of data to 11 years. The biggest challenges were making sure each of us were working with the most up to date data and then if we needed to trim, modifying the code we had actually written already.\n",
    "\n",
    "## Classification\n",
    "We used a Random, Naive Bayes, Decision Tree, and Random Forest Classifier on these three datasets. Ultimately we deployed the Decision Tree to Heroku for its speed and its accuracy combined. \n",
    "\n",
    "===========================================\n",
    "MyDecisionTreeClassifier Results\n",
    "===========================================\n",
    "\n",
    "Melbourne accuracy = 0.71 & error rate = 0.29 \\\n",
    "Sydney accuracy = 0.73 & error rate = 0.27 \\\n",
    "Seattle accuracy = 0.62 & error rate = 0.38 \n",
    "\n",
    "\n",
    "## Ideas for Improvement\n",
    "1. Possibly specify by the month so we can have more accurate and applicable results.\n",
    "1. UI implementation so we can choose which of the 3 locations we want to predict for.\n",
    "1. Collect more data for Seattle and be more intentional about selection.\n",
    "\n",
    "## Sources and references\n",
    "+ [Australia Rain](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package)\n",
    "+ [Seattle Rain](https://www.kaggle.com/rtatman/did-it-rain-in-seattle-19482017/metadata)\n",
    "+ [Go Follow Gina!](https://www.youtube.com/playlist?list=PL7uPCUbavAWf66__MqJfMvFgDqN7ghLSo)\n",
    "+ [StackOverflow](https://stackoverflow.com)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
